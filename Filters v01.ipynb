{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842d85ba-70d1-4adc-b5a3-edaa445df944",
   "metadata": {},
   "source": [
    "## Importing Images Recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "580dfde6-9cb9-4a78-a263-ef048a500d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFilter\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d35a44-55b6-44ab-979b-e202ddfff245",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(\"./Input/*.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316b2c7-33cf-45ec-a2c6-c8fd38204c0c",
   "metadata": {},
   "source": [
    "## Adaptive Median Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99574b8-ad77-4da8-aa39-550003773775",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adaptive_median_filter(img, s=3, s_max=7):\n",
    "\n",
    "    x, y = img.shape\n",
    "    # Initialize result image\n",
    "    result = np.zeros_like(img)\n",
    "\n",
    "    # Traverse through image\n",
    "    for i in range(0, x):\n",
    "        for j in range(0, y):\n",
    "            # Set current filter size to starting filter size\n",
    "            s_cur = s\n",
    "            # While current filter size is smaller or equal to maximum filter size\n",
    "            while s_cur <= s_max:\n",
    "                # Create new filter list\n",
    "                filtr = []\n",
    "\n",
    "                filter_edge = s_cur//2\n",
    "\n",
    "                # Traverse through filter\n",
    "                for u in range(s_cur):\n",
    "                    for v in range(s_cur):\n",
    "                        # Get current position\n",
    "                        cur_x = (i + u - filter_edge)\n",
    "                        cur_y = (j + v - filter_edge)\n",
    "\n",
    "                        # Stay inside image boundaries\n",
    "                        if((cur_x >= 0) and (cur_y >= 0) and (cur_x < x) and (cur_y < y)):\n",
    "                            # Append value to filter list\n",
    "                            filtr.append(img[cur_x, cur_y])\n",
    "\n",
    "                            # Get value in center of filter region\n",
    "                            if cur_x == i and cur_y == j:\n",
    "                                z_xy = filtr[-1]\n",
    "\n",
    "                # Convert filter list to numpy array\n",
    "                filtr = np.asarray(filtr)\n",
    "                # Get minimum value in filter region\n",
    "                z_min = np.amin(filtr)\n",
    "                # Get maximum value in filter region\n",
    "                z_max = np.amax(filtr)\n",
    "                # Get median value in filter region\n",
    "                z_med = np.median(filtr)\n",
    "\n",
    "                # If z_med is not an impulse: check next case. else: increase window size\n",
    "                if z_min < z_med < z_max:\n",
    "                    # If z_xy is not an impulse: output z_xy. else: output z_med\n",
    "                    if z_min < z_xy < z_max:\n",
    "                        result[i, j] = z_xy\n",
    "                    else:\n",
    "                        result[i, j] = z_med\n",
    "                    # Break to exit while loop\n",
    "                    break\n",
    "                else:\n",
    "                    s_cur += 2\n",
    "\n",
    "            else:\n",
    "                result[i, j] = z_med # Output median value if maximum window size has been surpassed\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56027832-78c6-434f-977c-2c96231a3ea4",
   "metadata": {},
   "source": [
    "## Adaptive Local Noise Reduction Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78e6707-b3fc-4548-815c-39c476183e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_g = np.var(input_images[0])\n",
    "# print(var_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7615e082-6f7d-4996-9f5e-61b477396c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adaptive_lnr_filter(img, var_g, s=3):\n",
    "\n",
    "    x, y = img.shape\n",
    "    # Initialize result image\n",
    "    result = np.zeros_like(img)\n",
    "\n",
    "    filter_edge = s//2\n",
    "\n",
    "    # Traverse through image\n",
    "    for i in range(0,x):\n",
    "        for j in range(0,y):\n",
    "            # Create new filter list\n",
    "            filtr = []\n",
    "\n",
    "            # Traverse through filter\n",
    "            for u in range(s):\n",
    "                for v in range(s):\n",
    "                    # Get current position\n",
    "                    cur_x = (i + u - filter_edge)\n",
    "                    cur_y = (j + v - filter_edge)\n",
    "\n",
    "                    # Stay inside image boundaries\n",
    "                    if((cur_x >= 0) and (cur_y >= 0) and (cur_x < x) and (cur_y < y)):\n",
    "                        # Append value to filter list\n",
    "                        filtr.append(img[cur_x, cur_y])\n",
    "\n",
    "            # Convert filter list to numpy array\n",
    "            filtr = np.array(filtr)\n",
    "            # Get local mean from filter\n",
    "            mean_l = np.mean(filtr)\n",
    "            # Get local variance from filter\n",
    "            var_l = np.var(filtr)\n",
    "\n",
    "            # If local variance is smaller than global variance, set ratio to 1\n",
    "            if var_g <= var_l:\n",
    "                r = var_g / var_l\n",
    "            else:\n",
    "                r = 1\n",
    "            # Get the output value and round off to nearest integer\n",
    "            result[i, j] = img[i, j] - (r * (img[i, j] - mean_l))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66850fc2-076c-4493-b044-eaec2ea20d16",
   "metadata": {},
   "source": [
    "## Output Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48455abe-a5a0-4bc3-ac92-215476883aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmenders\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "input_images = []\n",
    "grayscale_images = []\n",
    "\n",
    "output_images_med = []\n",
    "output_images_lnr = []\n",
    "\n",
    "for img in images:\n",
    "    image_org = Image.open(img)\n",
    "    image = np.array(image_org)\n",
    "    \n",
    "    input_images.append(image)\n",
    "    \n",
    "    grayscale_image = rgb2gray(image) #outputs a grayscaled image\n",
    "    grayscale_images.append(grayscale_image)\n",
    "    \n",
    "    output = adaptive_median_filter(grayscale_image, 3, 7)\n",
    "    output_images_med.append(output)\n",
    "    \n",
    "    output = adaptive_lnr_filter(grayscale_image , var_g)\n",
    "    output_images_lnr.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45f9f3-ec3a-478c-844f-07a23d6df457",
   "metadata": {},
   "source": [
    "## Signal to Noise Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccb464a9-e2d2-4ef7-a88c-2bed0742e39e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def signaltonoise(a, axis=None, ddof=0):  #axis = None for single value output \n",
    "    a = np.asanyarray(a)\n",
    "    m = a.mean(axis)\n",
    "    sd = a.std(axis=axis, ddof=ddof)\n",
    "    return np.where(sd == 0, 0, m/sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62f64091-a039-4d84-afd7-5c699fc5e0f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR of Input Image no. 1 : 2.128098666610694\n",
      "SNR of Input Image no. 2 : 3.2918972157093718\n",
      "SNR of Input Image no. 3 : 3.431399672412856\n",
      "SNR of Input Image no. 4 : 3.059226953388642\n",
      "SNR of Input Image no. 5 : 2.267202557563438\n"
     ]
    }
   ],
   "source": [
    "# FOR INPUT IMAGES\n",
    "n = 1\n",
    "for img in input_images:\n",
    "    print(f'SNR of Input Image no. {n} :',signaltonoise(img,axis=None))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96c601f8-4f7d-4b8a-a4f5-56fdd0bf4d67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR of AMF Output Image no. 1 : 2.130421814846192\n",
      "SNR of AMF Output Image no. 2 : 3.299930378520058\n",
      "SNR of AMF Output Image no. 3 : 3.4354787121674764\n",
      "SNR of AMF Output Image no. 4 : 3.0648630953701708\n",
      "SNR of AMF Output Image no. 5 : 2.2697847655527386\n"
     ]
    }
   ],
   "source": [
    "# FOR OUTPUT IMAGES OF ADAPTIVE MEDIAN FILTER\n",
    "n = 1\n",
    "for img in output_images_med:\n",
    "    print(f'SNR of AMF Output Image no. {n} :',signaltonoise(img,axis=None))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c73efdd-3121-4ba3-93b3-d36363206de5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR of ANLR Output Image no. 1 : 2.1357630879158727\n",
      "SNR of ANLR Output Image no. 2 : 3.316781278421003\n",
      "SNR of ANLR Output Image no. 3 : 3.4495881525384795\n",
      "SNR of ANLR Output Image no. 4 : 3.0812519532271008\n",
      "SNR of ANLR Output Image no. 5 : 2.271154329334771\n"
     ]
    }
   ],
   "source": [
    "# FOR OUTPUT IMAGES OF ADAPTIVE LOCAL NOISE REDUCTION FILTER\n",
    "n = 1\n",
    "for img in output_images_lnr:\n",
    "    print(f'SNR of ANLR Output Image no. {n} :',signaltonoise(img,axis=None))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420aa38-1e66-41c5-9f04-a26016e30089",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbbf815e-02f9-4784-a575-996fe5bf194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import greycomatrix\n",
    "def _entropy(image):\n",
    "    glcm = np.squeeze(greycomatrix(image, distances=[1], angles=[0], symmetric=True, normed=True))\n",
    "    entropy = -np.sum(glcm*np.log2(glcm + (glcm==0)))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff0f1e4e-24c1-4ed0-9e96-d4e5b34d95ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of Input Image no. 1 : 12.133920599166379\n",
      "Entropy of Input Image no. 2 : 10.764561028414455\n",
      "Entropy of Input Image no. 3 : 11.29525997931554\n",
      "Entropy of Input Image no. 4 : 11.370063274497461\n",
      "Entropy of Input Image no. 5 : 11.320869714157897\n"
     ]
    }
   ],
   "source": [
    "# FOR INPUT IMAGES\n",
    "n = 1\n",
    "for img in input_images:\n",
    "    print(f'Entropy of Input Image no. {n} :',_entropy(img))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "590f3255-c170-4559-abb6-232bf742fa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of AMF Output Image no. 1 : 12.045095044793662\n",
      "Entropy of AMF Output Image no. 2 : 10.6628580654782\n",
      "Entropy of AMF Output Image no. 3 : 11.162306087796674\n",
      "Entropy of AMF Output Image no. 4 : 11.249916612384313\n",
      "Entropy of AMF Output Image no. 5 : 11.237540902388114\n"
     ]
    }
   ],
   "source": [
    "# FOR OUTPUT IMAGES OF ADAPTIVE MEDIAN FILTER\n",
    "n = 1\n",
    "for img in output_images_med:\n",
    "    print(f'Entropy of AMF Output Image no. {n} :',_entropy(img))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c16eea5e-0e5c-442b-b1d9-cad79a053d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of ANLR Output Image no. 1 : 11.848038800281103\n",
      "Entropy of ANLR Output Image no. 2 : 10.499399085465814\n",
      "Entropy of ANLR Output Image no. 3 : 10.90667950117403\n",
      "Entropy of ANLR Output Image no. 4 : 10.946891362083917\n",
      "Entropy of ANLR Output Image no. 5 : 11.062837457228149\n"
     ]
    }
   ],
   "source": [
    "# FOR OUTPUT IMAGES OF ADAPTIVE LOCAL NOISE REDUCTION FILTER\n",
    "n = 1\n",
    "for img in output_images_lnr:\n",
    "    print(f'Entropy of ANLR Output Image no. {n} :',_entropy(img))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f16e2-aa9b-4fe8-8fac-d772252f06fe",
   "metadata": {},
   "source": [
    "## Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dafe0879-3186-4180-a94c-a4586b2b27bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_brightness(img):\n",
    "    m , n = img.shape    \n",
    "\n",
    "    pixel_sum = sum(sum(img))\n",
    "    \n",
    "    return pixel_sum/(m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9326b7ea-f6b7-4e0a-bc52-59af9cec1a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brightness of Input Image no. 1 : 0.4137313900291943\n",
      "Brightness of Input Image no. 2 : 0.43989440833995147\n",
      "Brightness of Input Image no. 3 : 0.433496269616671\n",
      "Brightness of Input Image no. 4 : 0.4230937014127359\n",
      "Brightness of Input Image no. 5 : 0.4396483260813637\n"
     ]
    }
   ],
   "source": [
    "# FOR INPUT IMAGES\n",
    "n = 1\n",
    "for img in input_images:\n",
    "    print(f'Brightness of Input Image no. {n} :',calculate_brightness(img))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69945d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brightness of AMF Output Image no. 1 : 0.3979933110367893\n",
      "Brightness of AMF Output Image no. 2 : 0.4498383686983367\n",
      "Brightness of AMF Output Image no. 3 : 0.4263486985604188\n",
      "Brightness of AMF Output Image no. 4 : 0.40410062527264795\n",
      "Brightness of AMF Output Image no. 5 : 0.4366953389783112\n"
     ]
    }
   ],
   "source": [
    "# FOR OUTPUT IMAGES OF ADAPTIVE MEDIAN FILTER\n",
    "n = 1\n",
    "for img in output_images_med:\n",
    "    print(f'Brightness of AMF Output Image no. {n} :',calculate_brightness(img))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "239caf75-85a2-454d-b2a7-e6663df5d897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brightness of ANLR Output Image no. 1 : 0.43205333273677027\n",
      "Brightness of ANLR Output Image no. 2 : 0.42595720405812015\n",
      "Brightness of ANLR Output Image no. 3 : 0.4331942595720406\n",
      "Brightness of ANLR Output Image no. 4 : 0.43289224952741023\n",
      "Brightness of ANLR Output Image no. 5 : 0.40067784476683704\n"
     ]
    }
   ],
   "source": [
    "# FOR OUTPUT IMAGES OF ADAPTIVE LOCAL NOISE REDUCTION FILTER\n",
    "n = 1\n",
    "for img in output_images_lnr:\n",
    "    print(f'Brightness of ANLR Output Image no. {n} :',calculate_brightness(img))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c183b-29a9-4423-8699-e0aaefb90c18",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f43cab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contrast(img):\n",
    "    m , n = img.shape\n",
    "    brightness = calculate_brightness(img)\n",
    "\n",
    "    \n",
    "    image = img.flatten()\n",
    "    \n",
    "    total = 0\n",
    "    for pixel in image:\n",
    "        val = pow((pixel - brightness),2)\n",
    "        total += val\n",
    "    \n",
    "    result = math.sqrt((1/(m*n))*total)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "347f726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast of Input Image no. 1 : 137.15518032498625\n",
      "Contrast of Input Image no. 2 : 177.63225902481636\n",
      "Contrast of Input Image no. 3 : 142.5719482889602\n",
      "Contrast of Input Image no. 4 : 137.51117430897094\n",
      "Contrast of Input Image no. 5 : 110.44314360935195\n"
     ]
    }
   ],
   "source": [
    "# FOR INPUT IMAGES\n",
    "n = 1\n",
    "for img in input_images:\n",
    "    print(f'Contrast of Input Image no. {n} :',calculate_contrast(img))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56705dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast of AMF Output Image no. 1 : 137.12800895474533\n",
      "Contrast of AMF Output Image no. 2 : 177.5366284308088\n",
      "Contrast of AMF Output Image no. 3 : 142.53716718365675\n",
      "Contrast of AMF Output Image no. 4 : 137.40639860358706\n",
      "Contrast of AMF Output Image no. 5 : 110.43140229603948\n"
     ]
    }
   ],
   "source": [
    "# FOR OUTPUT IMAGES OF ADAPTIVE MEDIAN FILTER\n",
    "n = 1\n",
    "for img in output_images_med:\n",
    "    print(f'Contrast of AMF Output Image no. {n} :',calculate_contrast(img))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d62f5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast of ANLR Output Image no. 1 : 136.57620242590764\n",
      "Contrast of ANLR Output Image no. 2 : 177.06968489890397\n",
      "Contrast of ANLR Output Image no. 3 : 142.044798567778\n",
      "Contrast of ANLR Output Image no. 4 : 136.87512718032767\n",
      "Contrast of ANLR Output Image no. 5 : 109.97605957350747\n"
     ]
    }
   ],
   "source": [
    "# FOR OUTPUT IMAGES OF ADAPTIVE LOCAL NOISE REDUCTION FILTER\n",
    "n = 1\n",
    "for img in output_images_lnr:\n",
    "    print(f'Contrast of ANLR Output Image no. {n} :',calculate_contrast(img))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e79e1-6b4d-4cfc-ac1b-270f8536cafd",
   "metadata": {},
   "source": [
    "## Saving Images in Output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61813f0c-5c8c-4ced-92e8-a04bb1c910ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "for img in output_images_lnr:\n",
    "    image = Image.fromarray(img)\n",
    "    image.save(f\"./Output/output{n}.png\")\n",
    "    n += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
